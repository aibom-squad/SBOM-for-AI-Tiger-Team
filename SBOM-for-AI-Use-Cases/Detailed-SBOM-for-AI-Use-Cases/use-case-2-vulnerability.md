# Use Case 2: Vulnerability and Incident Management

[Back to Table of Contents](../../README.md#table-of-contents)

## Problem Statement

The rapid integration of AI into organizational workflows has introduced new risks, particularly in managing security vulnerabilities tied to AI models and datasets. Risk teams, IT departments, and cybersecurity professionals must rapidly assess and respond to issues within AI systems. However, traditional workflows for vulnerability management often fail to address AI-specific challenges, leading to gaps in visibility and traceability.

Traditional vulnerability management relies on databases of known vulnerabilities and software identifiers to detect threats and associate them with affected components. In contrast, vulnerabilities in AI systems are often more complex and may arise from issues within AI models, the datasets used to train them, or the context in which they operate. Factors such as bias, ethical considerations, or safety concerns are not captured by the traditional frameworks used for software vulnerabilities, further complicating AI-specific risk management.  

To address these challenges, organizations must first establish a **comprehensive inventory of AI models, datasets, and dependencies**, and **map them to applications, services, and business processes**. This foundational mapping supports risk prioritization and provides the operational context needed for effective response.

The **LAION-5B incident of December 2023** illustrates these challenges clearly. When a widely used dataset—used to train models like Stable Diffusion—was found to contain thousands of instances of CSAM (child sexual abuse material), organizations worldwide were left scrambling to answer critical questions:

*   Have any of our models been trained on this dataset?

*   Are we using Stable Diffusion or any derivatives in production?

*   What business services or customer-facing products might be affected?

Answering these questions requires more than ad hoc documentation. It demands a **standardized, machine-readable representation of AI system components**—one that can be used to **aggregate, track, and operationalize metadata** across the AI lifecycle. This is where the concept of an **SBOM for AI** becomes essential.
<br><br>

## Benefits

*   **Faster Incident Response** – SBOM for AIs make it easier to identify which models or datasets are affected during an incident, enabling quicker containment and remediation.

*   **Clear Asset Inventory** – By maintaining a machine-readable inventory of AI components and their relationships to business systems, organizations gain critical visibility needed for efficient risk triage.

*   **Proactive Risk Management** – Up-to-date SBOMs support proactive scanning and monitoring of AI dependencies, helping to identify and mitigate potential risks in the AI lifecycle before they escalate.

*   **Improved Transparency and Accountability** – SBOM for AIs enhance visibility across teams and stakeholders, supporting informed decision-making and compliance with internal governance practices.

*   **Streamlined Collaboration** – The standardized, tool-agnostic format of SBOM for AIs allows seamless integration with existing cybersecurity tools and facilitates secure information sharing across teams or organizations.
<br><br>

## Example Scenarios

### Scenario 1: A Different Approach to LAION-5B

#### Context

In December 2023, the LAION-5B dataset—one of the largest publicly available AI training datasets—was discovered to contain child sexual abuse material (CSAM). This dataset had been used to train popular AI models, including Stable Diffusion, which many organizations had incorporated into their products and services. The discovery led to widespread concern, as companies scrambled to determine whether their AI models were affected.

Organizations faced critical questions:

*   Have we trained any of our models on the compromised dataset?

*   Do we use Stable Diffusion anywhere in our enterprise?

*   Which business applications and services might be impacted?

Without a structured SBOM for AI, answering these questions would  require manual investigations, compilation of fragmented asset inventories, and reliance on documentation that may not be complete. This results in delayed response efforts and increased regulatory and reputational risks.

#### How an SBOM for AI and Automation Could Have Changed the Response

1.  **<u>Automated Impact Analysis</u>**: The SBOM for AI would have provided an automated, real-time inventory of all AI models and datasets used within the organization. Security teams could have instantly queried their SBOM for AI database to identify whether any AI assets had dependencies on LAION-5B or Stable Diffusion.

    *   **Immediate detection of affected models**: SBOM for AI metadata would have flagged models trained on LAION-5B, enabling instant risk assessment.

    *   **Dependency mapping**: SBOM for AI relationships would have traced the impact across derived models and applications, revealing where compromised AI outputs were being used.

2.  **<u>Rapid Incident Containment</u>**: With SBOM for AI automation integrated into the organization's security stack, an incident response workflow could have been triggered as soon as the LAION-5B compromise was reported.

    *   **Automated alerts**: Security teams would have received instant notifications if affected AI models were deployed in production systems.

    *   **Access controls and quarantine**: AI models linked to LAION-5B could have been automatically flagged for removal or restricted from further deployment.

    *   **Audit trail for compliance**: SBOM for AI records would have provided a clear history of how and where the dataset was used, supporting legal and regulatory responses.

3.  **<u>Coordinated Remediation and Recovery</u>**: Once affected AI assets were identified, response teams could have taken swift action to mitigate risks.

    *   **Retraining and validation**: Organizations could have systematically replaced compromised training data, retraining models using verified datasets.

    *   **Policy enforcement**: SBOM for AI policies could have been updated to prevent future usage of datasets flagged for security, ethical, or legal concerns.

    *   **Stakeholder communication**: Security, compliance, and business teams would have been automatically notified about remediation progress and risk mitigation strategies.

#### Outcome: A Faster, More Automated Response

By leveraging SBOM for AIs, organizations could have transformed their incident response to the LAION-5B crisis from a weeks-long manual effort into an automated, structured process. Instead of scrambling to map affected models and datasets, security teams would have had immediate visibility, enabling faster remediation and reducing operational and reputational risks.

